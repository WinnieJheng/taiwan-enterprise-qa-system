{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11340972,"sourceType":"datasetVersion","datasetId":7085907},{"sourceId":11340978,"sourceType":"datasetVersion","datasetId":7085846},{"sourceId":11340987,"sourceType":"datasetVersion","datasetId":7085915}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🤖💼 Capstone Project: Taiwan Enterprise QA System（台灣企業內部智能問答系統）\n## 🔍Project Introduction（專案簡介）\n\n### 👉 Blogpost: https://hackmd.io/zmmxNnCrQMWTchRSEE63Mg\n### 👉 YouTube video: https://youtu.be/66rlfSux6OU\n\nThis project is the capstone submission for the Gen AI Intensive Course (Q1 2025), co-hosted by Google and Kaggle. The core of this project is a prototype of a Generative AI-powered internal Q&A assistant, specifically designed for a Taiwan-based company. The system aims to assist employees in efficiently accessing information related to HR, finance, and IT policies, thereby reducing the repetitive workload on administrative staff.\n\nBuilt on the Retrieval-Augmented Generation (RAG) architecture, this solution integrates the Google Gemini API with ChromaDB, enabling the assistant to retrieve the most relevant content from internal documents and generate accurate, semantically coherent responses in Traditional Chinese. This project demonstrates the practical potential and creative applications of LLMs in internal business environments in Taiwan.\n\n---\n\n本專案為參加 2025 年第一季 Google x Kaggle《Gen AI Intensive》課程之結業專題。專案核心為一個以生成式 AI 技術為基礎，專為台灣公司設計的「內部問答機器人原型」，旨在協助企業內部員工更有效率地查詢人資、財務與資訊部門的相關制度資訊，減少重複性行政詢答所耗費的人工成本與時間。\n\n本系統整合了 Google Gemini API 與 ChromaDB 向量資料庫，實現 Retrieval-Augmented Generation（RAG）架構，能根據使用者問題，自內部文件中擷取最相關段落，再搭配大語言模型生成精準、語意連貫的中文回答。透過此專案，展示了 LLM 在繁體中文企業內部應用上的可行性與創意潛力。","metadata":{"_uuid":"149bd171-8ab0-4440-a9f6-41b75d7dbbf3","_cell_guid":"d23c84ad-1eb4-4084-a980-9c236772d801","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## ⚙️ Technologies Used（使用技術）\n\nThis project demonstrates **three official Gen AI capabilities** as defined in the capstone criteria:\n\n1. **Document Understanding**  \n　The system loads and parses internal `.docx` files (HR, Finance, IT), segments them into meaningful paragraphs, and prepares them for semantic embedding. This simulates real-world enterprise documents and enables accurate, context-aware retrieval.\n\n2. **Embeddings & Vector Database (Vector Search)**  \n　Using the `text-embedding-004` model from the Google Gemini API, each document chunk is embedded into semantic vectors and stored in ChromaDB, a vector database. Queries are also embedded and matched using vector similarity search.\n\n3. **Retrieval-Augmented Generation (RAG)**  \n　When a user asks a question, the system retrieves the most relevant document chunks and injects them into a prompt. Gemini then generates grounded answers in Traditional Chinese, ensuring responses are accurate and aligned with company policies.  \n　To ensure stable and consistent answers, the model uses a fixed low-temperature setting (`temperature=0`), which reduces hallucination and enhances response reliability in enterprise use cases.\n\nThese three capabilities form a complete RAG-based Q&A system for internal enterprise use. The assistant demonstrates the practical integration of LLMs into real-world workflows and offers a foundation for future expansion.\n\n---\n\n本專案依照官方定義，實作並展示了 **三項指定的 Gen AI 能力**：\n\n1. **文件理解（Document Understanding）**  \n　系統讀取 `.docx` 格式的公司內部規章文件（人資、財務、資訊），並切分為段落語意單位，作為語意向量化與檢索的基礎，模擬企業真實文件應用場景。\n\n2. **語意向量與向量資料庫（Embeddings & Vector Search）**  \n　使用 Gemini 的 `text-embedding-004` 模型將每段內容轉為語意向量，並儲存在 ChromaDB 資料庫中。使用者提問後，系統透過語意相似度進行段落匹配與檢索。\n\n3. **檢索增強生成（Retrieval-Augmented Generation, RAG）**  \n　針對每個問題，系統自資料庫找出最相關段落，插入 prompt 中，並由 Gemini 模型產生結合文件知識的回覆，保證回覆語意連貫且符合公司制度。  \n　此外，系統設定固定低溫度（`temperature=0`）以強化輸出一致性並降低幻覺風險，提升企業環境下的信賴度與可控性。\n\n這三項技術整合形成一個可實際應用的企業內部問答解決方案，展示生成式 AI 技術在繁體中文場域的落地潛力與擴展性。","metadata":{"_uuid":"76879500-aef0-4775-934a-1594d2ebb51c","_cell_guid":"4e697777-7973-48ed-a844-c08737a8ceb9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 🔄 System Workflow & Architecture（系統流程與架構）\n\nThis project follows a modular architecture based on the Retrieval-Augmented Generation (RAG) pipeline. The full system flow includes document ingestion, embedding generation, vector indexing, similarity search, and response generation. The detailed steps are as follows:\n\n1. Upload `.docx` files containing internal policy documents (e.g., HR, Finance, IT)\n2. Segment documents into smaller text chunks (typically at paragraph level)\n3. Convert each chunk into a semantic vector using `text-embedding-004` (Gemini embedding model)\n4. Store the vectors in ChromaDB to enable semantic similarity search\n5. User submits a natural language query\n6. The system embeds the query and retrieves the top-N most relevant chunks\n7. Retrieved chunks are inserted into a prompt and passed to `generate_content()` for response generation\n8. A fluent and contextually grounded answer is returned in Traditional Chinese\n\n---\n\n本系統採用 RAG（檢索增強生成）架構，流程模組化、可擴展，涵蓋從資料前處理到回答生成的完整鏈條。具體步驟如下：\n\n1. 上傳包含公司內部規章的 `.docx` 文件（如人資、財務、資訊等）\n2. 將文件切分為段落單位的文字區塊\n3. 使用 Gemini 的 `text-embedding-004` 模型將每段轉為語意向量\n4. 將向量儲存於 ChromaDB 向量資料庫中，便於後續語意檢索\n5. 使用者輸入自然語言問題作為查詢\n6. 系統將問題向量化，並從資料庫中找出最相關的 N 段文字\n7. 將檢索段落插入 prompt 中，送入 Gemini `generate_content()` 模型進行回答生成\n8. 最終回傳一則流暢、依據文件內容生成的繁體中文回答","metadata":{"_uuid":"d902421d-dd41-47df-9905-a263e849f33e","_cell_guid":"dbbf49bf-0621-44ec-903a-85094d9b7843","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 💡 Use Cases & Innovation Highlights（應用場景與創意亮點）\n\nThis internal Q&A assistant was developed to address a real pain point commonly found in Taiwan-based companies: the repetitive administrative questions faced by HR, IT, and Finance departments. Employees often inquire about topics such as leave policies, reimbursement procedures, account permissions, and software installations—questions that are typically answered manually by staff over and over again.\n\nThe assistant enables employees to ask natural language questions and receive document-grounded answers instantly, improving response speed and reducing the burden on administrative teams. This boosts operational efficiency while freeing up staff to focus on higher-value tasks.\n\n---\n \n本問答機器人專案聚焦於台灣企業中常見的行政痛點：來自員工的大量重複性詢問，經常壓垮人資、資訊與財務部門的工作效率。例如請假制度、報帳流程、系統帳號權限、軟體安裝方式等問題，皆需仰賴人工反覆說明與回覆。\n\n本系統可讓員工以自然語言提問，並立即取得來自公司內部文件的準確回答，不僅提升查詢效率，也有效降低行政部門的工作負擔，使其能專注於更具策略性的任務上。","metadata":{"_uuid":"bbc04ac7-3aa7-4abc-bef7-cbaa955f69a3","_cell_guid":"7e637dc6-07d6-40f8-a0b2-7b1759f91519","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 🔚 Conclusion & Future Directions（結語與未來展望）\n\nThis project demonstrates a practical and scalable application of Generative AI technologies in a real-world enterprise setting. From embedding document knowledge to generating stable, policy-aligned responses in Traditional Chinese, the system successfully integrates Gemini's generative capabilities with ChromaDB's retrieval strength in a full RAG pipeline.\n\nThrough this hands-on experience, I gained valuable insights into prompt design, vector database management, and building reliable Q&A workflows with LLMs. More importantly, I learned how to align AI system design with actual user needs in a business environment.\n\nLooking ahead, this system has strong potential to be deployed within a real organization—either as a chatbot widget on internal portals or integrated with existing employee helpdesk systems. Future improvements include multi-turn conversations, voice interface, support for additional document formats (e.g., PDFs, Google Docs), and **FAQ shortcut buttons** to improve accessibility and ease of use for employees.\n\n---\n\n本專案成功展現了生成式 AI 技術在企業內部場域的實用性與可擴展性。透過向量化內部文件內容，搭配穩定生成的繁體中文回覆，系統完整實現了以 Gemini 與 ChromaDB 為核心的 RAG 架構，並能對應企業制度問答需求。\n\n在本次實作中，我實際操作了 prompt 設計、向量資料庫建構與 LLM 應用流程，也學會了如何從使用者角度出發，設計出貼近需求的 AI 系統。\n\n此系統具備導入企業實務的潛力，例如可作為內部入口網站的智慧客服，或串接既有的人力資源與資訊服務系統。功能上則可進一步擴充：多輪對話、語音查詢介面、更多文件格式支援（如 PDF、Google 文件），以及**FAQ 快速查詢按鈕**等輔助功能，提升使用體驗與資訊可近性。","metadata":{"_uuid":"75d5f3e8-ccb1-4dfc-ac38-7a3fca9cc587","_cell_guid":"cee4ed54-ba27-423a-a40e-27b77c341809","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## ⚙️ Setup（環境安裝）\n\n### 📦 Install dependencies（安裝依賴套件）\n\nThis notebook uses the following libraries:\n\n- `google-genai==1.7.0`: Gemini API client for text generation  \n- `chromadb==0.6.3`: Vector database for semantic search  \n- `python-docx`: For parsing internal `.docx` documents  \n- `protobuf==3.20.3`, `google-api-core==2.11.1`: Compatible versions to avoid dependency conflicts\n\nTo prevent installation errors or warnings caused by background packages  \n(such as `google-cloud-bigtable`, `automl`, or `pandas-gbq`),  \nwe first uninstall these **unused but pre-installed** packages.  \nThis ensures a smooth setup with **no pip errors or warnings**.\n\n---\n\n本 Notebook 使用以下核心套件：\n\n- `google-genai==1.7.0`：呼叫 Gemini API 生成回答  \n- `chromadb==0.6.3`：用於語意搜尋的向量資料庫  \n- `python-docx`：讀取公司內部 Word 文件  \n- `protobuf==3.20.3`, `google-api-core==2.11.1`：穩定相容版本，避免套件依賴衝突\n\n由於 Kaggle 環境中預設安裝了一些非本專案使用的 Google 套件（如 `pandas-gbq`, `bigtable`, `automl` 等），  \n這些套件會對 `protobuf` 或 `google-api-core` 有不同的版本需求，導致安裝時出現錯誤或警告。\n\n因此我們先移除這些不必要的預設套件，再安裝專案真正需要的相容版本，確保安裝過程**零錯誤、零衝突**，提交時更安心。","metadata":{"_uuid":"8c71e63c-4595-4cc8-9a6d-3bc705d15634","_cell_guid":"d4cdd36b-0b20-48a9-bb56-8f0d48ee09c9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 🧹 Step 1: 移除預設環境中可能引發依賴衝突的套件\n!pip uninstall -qqy jupyterlab kfp protobuf google-api-core tensorflow \\\n                   google-cloud-bigtable google-cloud-automl pandas-gbq\n\n# ✅ Step 2: 安裝本專案所需的相容版本套件，確保不會出現任何安裝錯誤\n!pip install -qU \\\n    google-genai==1.7.0 \\\n    chromadb==0.6.3 \\\n    python-docx \\\n    protobuf==3.20.3 \\\n    google-api-core==2.11.1","metadata":{"_uuid":"fef07bc4-b46c-4f66-8113-b5c845e2c76c","_cell_guid":"2d8f8fbb-c982-4537-8575-e1c310cd9179","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:51:14.267015Z","iopub.execute_input":"2025-04-20T15:51:14.267427Z","iopub.status.idle":"2025-04-20T15:52:50.026830Z","shell.execute_reply.started":"2025-04-20T15:51:14.267396Z","shell.execute_reply":"2025-04-20T15:52:50.024907Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 📥 Import Gemini SDK（匯入 Gemini SDK 並確認版本）\n  \nWe import the core modules from the `google.genai` library and display the installed version to ensure correct API usage.\n\n匯入 Gemini API 的核心模組，並顯示目前安裝版本，以確保後續使用的 API 正確性。","metadata":{"_uuid":"61b2c8b8-35e2-42a2-addd-8d8cbfeaa410","_cell_guid":"42df0884-2a3c-46a2-8119-c3b8502a89b2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown\n\ngenai.__version__","metadata":{"_uuid":"9ec438bf-f692-42bf-8e71-6444c6473d8f","_cell_guid":"7c3dfb6f-0881-4da7-a73e-3099a608e9a4","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:50.029341Z","iopub.execute_input":"2025-04-20T15:52:50.029759Z","iopub.status.idle":"2025-04-20T15:52:51.753238Z","shell.execute_reply.started":"2025-04-20T15:52:50.029722Z","shell.execute_reply":"2025-04-20T15:52:51.752223Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔐 Load Gemini API Key（從 Kaggle Secret 載入 Gemini 金鑰）\n  \nTo authenticate access to Gemini API, the API key is retrieved securely from Kaggle Secrets. This avoids exposing the key in plain text.\n \n為了安全地使用 Gemini API，本專案透過 Kaggle Secrets 取得 API 金鑰，避免將金鑰明文寫入程式中。","metadata":{"_uuid":"87276fa4-faaf-4193-a127-695fcf08c20e","_cell_guid":"4a99f54c-821d-4723-8569-ca87ebea0f16","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"_uuid":"a7d2402f-9bda-4c1f-baec-a9288cf311aa","_cell_guid":"518d6fd9-184d-4be7-b565-3c17e3efbbd5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:51.754979Z","iopub.execute_input":"2025-04-20T15:52:51.755473Z","iopub.status.idle":"2025-04-20T15:52:51.861062Z","shell.execute_reply.started":"2025-04-20T15:52:51.755444Z","shell.execute_reply":"2025-04-20T15:52:51.859996Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 📄 Load Internal Documents（載入公司內部文件）\n  \nThis step loads three internal `.docx` files related to HR, Finance, and IT policies using the `python-docx` library. Text is cleaned and combined into a list for later processing.\n \nThe three internal documents (HR, Finance, and IT) used in this project are mock data manually created for testing purposes.  \nThe content was designed to simulate realistic company policy documents while avoiding the use of any sensitive or proprietary information.\n\n使用 `python-docx` 套件載入三份內部文件（人資、財務、資訊），並將每份文件中的段落整理為純文字，儲存於 list 供後續處理使用。\n\n本專案中使用的三份公司內部文件（人資、財務、資訊）皆為為測試目的所自製的模擬資料。  \n內容設計模擬真實公司制度說明，並未涉及任何敏感或真實商業資訊。","metadata":{"_uuid":"6b72a7a6-7b86-4d27-8623-ae518412df54","_cell_guid":"2f6ed738-2df0-438a-bffc-0312c2564253","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from docx import Document\n\ndef load_docx_text(path):\n    doc = Document(path)\n    return \"\\n\".join([para.text.strip() for para in doc.paragraphs if para.text.strip()])\n\n# 載入三份文件\nhr_doc = load_docx_text(\"/kaggle/input/company-hr-qa/HR_QA.docx\")\nfinance_doc = load_docx_text(\"/kaggle/input/company-finance-qa/Finance_QA.docx\")\nit_doc = load_docx_text(\"/kaggle/input/company-it-qa/IT_QA.docx\")\n\n# 存成一個 list\ndocuments = [hr_doc, finance_doc, it_doc]\n\n#檢查內容\nfor i, doc in enumerate(documents):\n    print(f\"Document {i+1} preview:\\n{doc[:300]}\\n{'-'*40}\")","metadata":{"_uuid":"1324c6cb-8e4f-4c5d-b452-5da365ee33ae","_cell_guid":"f4a3617d-97b7-493e-9d0a-9ce2c0bb17c6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:51.862908Z","iopub.execute_input":"2025-04-20T15:52:51.863303Z","iopub.status.idle":"2025-04-20T15:52:52.180090Z","shell.execute_reply.started":"2025-04-20T15:52:51.863263Z","shell.execute_reply":"2025-04-20T15:52:52.178835Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🤖 Initialize Gemini Client（初始化 Gemini 並列出支援模型）\n\nCreate a Gemini client instance and list available models that support `embedContent`. This ensures we are using a model compatible with the embedding task.\n\n初始化 Gemini 用戶端，並列出支援 `embedContent` 功能的模型，以確認所選模型可執行語意向量生成任務。","metadata":{"_uuid":"ca32f42c-8ab0-45be-b736-b901dfcf17e0","_cell_guid":"ce35622b-89ad-4dc6-8c36-750ce656ac8c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\n\nfor m in client.models.list():\n    if \"embedContent\" in m.supported_actions:\n        print(m.name)","metadata":{"_uuid":"64f3de22-c7a1-45e4-8621-747023b4913a","_cell_guid":"4ea350c4-90b7-469f-84f2-6eff0c05d251","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:52.181175Z","iopub.execute_input":"2025-04-20T15:52:52.181771Z","iopub.status.idle":"2025-04-20T15:52:52.833642Z","shell.execute_reply.started":"2025-04-20T15:52:52.181729Z","shell.execute_reply":"2025-04-20T15:52:52.832550Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🧠 Define GeminiEmbeddingFunction（定義嵌入函式供 ChromaDB 使用）\n \nDefine a custom class `GeminiEmbeddingFunction` that uses Gemini’s `text-embedding-004` model to generate embeddings. Includes retry logic for quota-based API errors.\n\n自訂一個嵌入函式 `GeminiEmbeddingFunction`，使用 Gemini 模型 `text-embedding-004` 進行語意向量生成，並加入自動重試機制，以處理配額錯誤。","metadata":{"_uuid":"2978f435-ba72-4fb9-b442-3602facfc9a5","_cell_guid":"e9c57b40-4190-472c-89c9-a62b470d7478","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from chromadb import Documents, EmbeddingFunction, Embeddings\nfrom google.api_core import retry\n\nfrom google.genai import types\n\n\n# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    # Specify whether to generate embeddings for documents, or queries\n    document_mode = True\n\n    @retry.Retry(predicate=is_retriable)\n    def __call__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        else:\n            embedding_task = \"retrieval_query\"\n\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\",\n            contents=input,\n            config=types.EmbedContentConfig(\n                task_type=embedding_task,\n            ),\n        )\n        return [e.values for e in response.embeddings]","metadata":{"_uuid":"cb3d3196-81c5-40e5-8b61-db6495ad336d","_cell_guid":"622d69fa-cade-4a5e-86b2-7beb81a753b6","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:52.834921Z","iopub.execute_input":"2025-04-20T15:52:52.835458Z","iopub.status.idle":"2025-04-20T15:52:53.772789Z","shell.execute_reply.started":"2025-04-20T15:52:52.835419Z","shell.execute_reply":"2025-04-20T15:52:53.771631Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 🗃️ Initialize Vector Store（初始化向量資料庫）\n \nSet up a ChromaDB vector database with the custom Gemini embedding function. Add the internal documents to the collection, ready for similarity-based retrieval.\n \n使用先前定義的 Gemini 嵌入函式初始化 ChromaDB，並將三份內部文件加入資料庫，以利後續語意相似度查詢。","metadata":{"_uuid":"ac57e1bd-8c91-4386-8850-111f8257c75f","_cell_guid":"f8dca81a-7ed6-437d-9824-9729c7c3e387","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import chromadb\n\nDB_NAME = \"googlecardb\"\n\nembed_fn = GeminiEmbeddingFunction()\nembed_fn.document_mode = True\n\nchroma_client = chromadb.Client()\ndb = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n\ndb.add(documents=documents, ids=[str(i) for i in range(len(documents))])","metadata":{"_uuid":"608a24b8-b0dc-4355-bbf7-5dc7163107dc","_cell_guid":"981b2432-7ffd-43c9-8676-661f1b613ce9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:53.773914Z","iopub.execute_input":"2025-04-20T15:52:53.774410Z","iopub.status.idle":"2025-04-20T15:52:54.377157Z","shell.execute_reply.started":"2025-04-20T15:52:53.774383Z","shell.execute_reply":"2025-04-20T15:52:54.376248Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 💬 Generate Answer from User Query（根據使用者提問產生回覆）\n\nThis part switches the embedding function into query mode, allowing user questions to be embedded and used for vector search. The system retrieves the top 3 most relevant document chunks from ChromaDB and injects them into a carefully designed prompt.\n\nThe prompt guides Gemini to act as a helpful assistant, replying in clear and friendly Traditional Chinese suitable for non-technical employees. If no relevant document content is found, the model is instructed to answer using general Gemini knowledge.\n\n此部分將嵌入函式切換為「查詢模式」，使使用者的問題也能進行語意嵌入與檢索。系統從資料庫中取出最相關的三段內部文件內容，並將其整合至精心設計的提示詞（prompt）中。\n\n提示內容引導 Gemini 扮演一位親切、知識豐富的助理，以自然流暢的【台灣繁體中文】回答問題，適合非技術背景的員工閱讀。若文件無相關資訊，則允許 Gemini 回復一般知識型答案。","metadata":{"_uuid":"c25faa1d-3133-4226-bb71-99d06d7c20a9","_cell_guid":"cfe0deaa-9f4b-4f4d-839c-047bee481ff8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"### 🧪 Test Four Query Scenarios（測試四種查詢情境）\n\nTo demonstrate the system's ability to handle different query types, we run four representative questions:\n\n- An HR-related question (document-supported)\n- A finance-related question (document-supported)\n- An IT-related question (document-supported)\n- A general question outside document scope (fallback to Gemini knowledge)\n\nEach question is used to perform vector search, and the retrieved passages are passed into the Gemini prompt to generate the final answer in Traditional Chinese.\n\n本段示範系統如何處理四種常見問題類型：\n\n- 人事部門相關（可由文件回答）\n- 財務制度相關（可由文件回答）\n- 資訊作業相關（可由文件回答）\n- 公司文件範圍外問題（由 Gemini 自有知識生成）\n\n每個問題皆經由語意檢索找出相關段落，並傳入 prompt 中請 Gemini 產生最終回應。","metadata":{"_uuid":"48bbca99-c00a-48f0-8c0f-0be201eda726","_cell_guid":"314888b5-2507-4ef6-8cc5-76c2516e5ec0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# 🧪 Four test queries (中文 + 英文解釋)\ntest_questions = [\n    (\"如何請病假\", \"HR-related question: How to apply for sick leave\"),\n    (\"如何報差旅費\", \"Finance-related question: How to file travel expense reimbursement\"),\n    (\"VPN無法連線\", \"IT-related question: VPN connection issue\"),\n    (\"Excel 的 SUM 函數怎麼寫？\", \"Out-of-scope question: How to write the SUM function in Excel?\")\n]\n\n# Set to query mode for question embedding\nembed_fn.document_mode = False\n\n# Iterate over each test query\nfor query_zh, label_en in test_questions:\n    print(f\"\\n🔎 {label_en}\\n❓ 中文問題：{query_zh}\")\n    \n    result = db.query(query_texts=[query_zh], n_results=3)\n    [all_passages] = result[\"documents\"]\n    \n    query_oneline = query_zh.replace(\"\\n\", \" \")\n\n    # Prompt includes instruction to return both Chinese and English\n    prompt = f\"\"\"你是一個親切且知識豐富的 AI 助理，會根據公司內部文件內容來回答問題。\n請以【台灣繁體中文】回答，語氣要自然、清楚，適合給非技術背景的一般員工閱讀。\n請務必用完整句子回答問題，內容要詳細，若有背景資料可以一起補充說明。\n請在中文回答後，**附上對應的英文翻譯版本**。\n如果提供的段落跟問題無關，你可以忽略那些段落。\n如果使用者問的是公司內部文件內容以外的問題，請以原本 Gemini 的數據生成回答，並同樣提供中英文版本。\n\nYou are a helpful and knowledgeable AI assistant. Please answer the following question based on internal company documents.\nRespond in **Traditional Chinese**, using clear and friendly language suitable for non-technical employees.\nPlease use complete sentences and provide detailed answers. If helpful, include relevant background information.\n**After the Traditional Chinese response, please provide an English translation of your answer.**\nIf any retrieved content is irrelevant, you may ignore it.\nIf the question is beyond the scope of internal documents, answer as Gemini normally would, and still provide both Chinese and English versions.\n\n問題 (Question)：{query_oneline}\n\"\"\"\n\n\n    # Append retrieved document passages\n    for passage in all_passages:\n        passage_oneline = passage.replace(\"\\n\", \" \")\n        prompt += f\"文件段落：{passage_oneline}\\n\"\n\n    # Generate answer using Gemini\n    low_temp_config = types.GenerateContentConfig(temperature=0)\n    answer = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=prompt,\n        config=low_temp_config\n    )\n\n\n    display(Markdown(f\"💡 Gemini 回答（Answer）：\\n\\n{answer.text}\\n\\n{'-'*80}\"))","metadata":{"_uuid":"fd2e5bc0-3d61-4cc2-9897-299f06325528","_cell_guid":"a14ab2bc-564a-4f11-b61a-a7ec601cccc2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:52:54.379372Z","iopub.execute_input":"2025-04-20T15:52:54.379695Z","iopub.status.idle":"2025-04-20T15:53:04.690380Z","shell.execute_reply.started":"2025-04-20T15:52:54.379668Z","shell.execute_reply":"2025-04-20T15:53:04.688727Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🧪 User Input Demo Section（使用者互動輸入區塊 ）\n\nIn the previous section, we demonstrated responses to four common office-related questions to showcase the system’s capability.\nThis section is designed to allow users to input their own question for a more personalized and interactive experience.\n\n⚠️ Note: Using Python's input() in a Kaggle Notebook will cause an ERROR during “Save Version” or auto-execution, interrupting the notebook run.\nTo avoid this, we set a default question \"請問要怎麼請病假？\" in the code as a fallback to ensure successful execution.\n\n🔧 If you’d like to enter your own question, simply uncomment the line below by removing the #:\n```python\n#query = input(\"請輸入您的問題：\")\n```\n前面我們示範了 **四種常見辦公室問題** 的查詢結果，讓大家快速了解系統的功能。  \n本區塊則是設計讓使用者可以 **自行輸入問題**，體驗更個人化的互動回應。\n\n⚠️ **提醒**：由於 Kaggle Notebook 在儲存（Save Version）或執行整份筆記時，無法處理 `input()` 函式，會導致程式出現 `ERROR` 並中斷執行。  \n因此在程式中，我們預設放入了一個範例問題 `\"請問要怎麼請病假？\"` 作為備用，確保 Notebook 可以順利執行。\n\n🔧 **如果您希望輸入自己的問題**，請將下列程式碼中的註解解除（刪除前面的 `#`）即可啟用互動輸入模式：\n```python\n#query = input(\"請輸入您的問題：\")\n```","metadata":{"_uuid":"f07e6418-1041-494e-85d0-be3f08b2caf9","_cell_guid":"99277a56-4ccd-4110-9ca3-70ad68392776","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Switch to query mode for embedding user questions (vs. document embedding)\nembed_fn.document_mode = False\n\n# 💬 預設查詢問題（Kaggle notebook 中使用）\n# For Kaggle notebook auto-execution: preset a default query\n# 📌 這樣設計是為了避免使用 input() 導致 notebook 無法自動執行並出現錯誤\n# 📌 This avoids using input() which causes errors during auto-execution in Kaggle notebooks\nquery = \"請問要怎麼請病假？\"  # Default query for demo purposes\n\n# ❗ 如果您希望自行輸入問題，請取消下方 input() 這行的註解\n# ❗ To input your own question, uncomment the line below\n#query = input(\"請輸入您的問題：\")  # Please enter your question (in Traditional Chinese)\n\n\n# Perform semantic search in ChromaDB using the input query\nresult = db.query(query_texts=[query], n_results=3)\n[all_passages] = result[\"documents\"]\n\n# Sanitize query by removing newline characters\nquery_oneline = query.replace(\"\\n\", \" \")\n\n# Build a bilingual prompt for Gemini model\nprompt = f\"\"\"你是一個親切且知識豐富的 AI 助理，會根據公司內部文件內容來回答問題。\n請以【台灣繁體中文】回答，語氣要自然、清楚，適合給非技術背景的一般員工閱讀。\n請務必用完整句子回答問題，內容要詳細，若有背景資料可以一起補充說明。\n請在中文回答後，**附上對應的英文翻譯版本**。\n如果提供的段落跟問題無關，你可以忽略那些段落。\n如果使用者問的是公司內部文件內容以外的問題，請以原本 Gemini 的數據生成回答，並同樣提供中英文版本。\n\nYou are a helpful and knowledgeable AI assistant. Please answer the following question based on internal company documents.\nRespond in **Traditional Chinese**, using clear and friendly language suitable for non-technical employees.\nPlease use complete sentences and provide detailed answers. If helpful, include relevant background information.\n**After the Traditional Chinese response, please provide an English translation of your answer.**\nIf any retrieved content is irrelevant, you may ignore it.\nIf the question is beyond the scope of internal documents, answer as Gemini normally would, and still provide both Chinese and English versions.\n\n問題 (Question)：{query_oneline}\n\"\"\"\n\n\n# Append retrieved document passages to the prompt\nfor passage in all_passages:\n    passage_oneline = passage.replace(\"\\n\", \" \")\n    prompt += f\"文件段落 (Document passage)：{passage_oneline}\\n\"\n\n# Send the prompt to Gemini model and generate an answer\nlow_temp_config = types.GenerateContentConfig(temperature=0)\nanswer = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=prompt,\n    config=low_temp_config\n)\n\n# Display the result as Markdown-formatted output\nMarkdown(answer.text)","metadata":{"_uuid":"5c7302bd-65f8-416b-aaa8-d6a0d4465516","_cell_guid":"0ac8917e-cf47-4e21-9b68-c64002491b8a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-04-20T15:53:04.692933Z","iopub.execute_input":"2025-04-20T15:53:04.693421Z","iopub.status.idle":"2025-04-20T15:53:06.017260Z","shell.execute_reply.started":"2025-04-20T15:53:04.693370Z","shell.execute_reply":"2025-04-20T15:53:06.016187Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}